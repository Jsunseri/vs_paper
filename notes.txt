- here I'll try to describe a general workflow, identifying the relevant
  scripts and any assumptions they make about associated inputs: 

  > creating a summary file with sdsorter (and pasting columns from accompanying CSVs) 
    + use make\_sdsorter\_summary.sh; takes path to top-level directory, assumes
      docked files are in that directory and named *\_docked.sdf.gz,
      looks for RFScore outputs as CSVs in the same directory, 
      looks for CNN output in subdirectories relative to the first directory
      and named after the model

    + creates output space-separated CSV with column names in first row, i.e. 
Rank Title Vina MW Target File RFScore-VS RFScore-4	dense\_seed0\_CNNaffinity dense\_seed0\_CNNscore dense\_seed1\_CNNaffinity dense\_seed1\_CNNscore dense\_seed2\_CNNaffinity dense\_seed2\_CNNscore dense\_seed3\_CNNaffinity dense\_seed3\_CNNscore dense\_seed4\_CNNaffinity dense\_seed4\_CNNscore crossdock\_default2018\_seed0\_CNNaffinity crossdock\_default2018\_seed0\_CNNscore crossdock\_default2018\_seed1\_CNNaffinity crossdock\_default2018\_seed1\_CNNscore crossdock\_default2018\_seed2\_CNNaffinity crossdock\_default2018\_seed2\_CNNscore crossdock\_default2018\_seed3\_CNNaffinity crossdock\_default2018\_seed3\_CNNscore crossdock\_default2018\_seed4\_CNNaffinity crossdock\_default2018\_seed4\_CNNscore general\_default2018\_seed0\_CNNaffinity general\_default2018\_seed0\_CNNscore general\_default2018\_seed1\_CNNaffinity general\_default2018\_seed1\_CNNscore general\_default2018\_seed2\_CNNaffinity general\_default2018\_seed2\_CNNscore general\_default2018\_seed3\_CNNaffinity general\_default2018\_seed3\_CNNscore general\_default2018\_seed4\_CNNaffinity general\_default2018\_seed4\_CNNscore 

    + subsequent steps take this output, which can be easily generated from
    whatever your score files are by just taking the sdsorter output and
    pasting any additional columns together

  > creating a pickle of a Pandas DataFrame of that info 

    + use sdsorter\_to\_pickle.py; takes list of dirnames that contain files
    named "sdsorter.summary" that have format as described in step 1 above,
    dumps out a pickle of the Pandas DataFrame created from that information
    (negating the Vina column and assigning a label based on the filename)

  > creating a summary file of predictions, typically per-compound 

    + make\_summary.py creates output CSV files with columns that are 
    LABEL PREDICTION TARGET TITLE METHOD, and the prediction is obtained by taking
    the maximum score after doing a groupby with respect to target and compound

    + summarize\_cnn\_alltrain\_predictions.py is an old version of this type of
    script that just does this for the CNN models, probably deprecated but
    keeping around just in case
 
  > calculating summary data
    
    + aucbytarget.py creates by-target grids of plots showing ROC curves for
    all methods whose ${methodname}.summary files are provided, as well as
    boxplots of AUCs, a modified version of a script from the original
    protein-ligand scoring paper so it's a bit of a mess

    + early\_enrichment.py creates by-target barplots and by-method boxplots of
    early enrichment and normalized early enrichment; the user can specify the
    ratio but it defaults to 1%

    + auc\_stripplot.py creates by-target stripplots of AUC, was basically a
    one-off that I didn't end up using
 
    + correlation\_summary.py computes correlations between predictions for
    different methods, over all compounds as well as conditioned on class; it
    also computes and plots the intersection between the highest-ranked
    compounds between different methods

    + scores\_vs\_poses.py does the grid of plots showing score distribution and
    correlation per class between all methods

    + composite\_scores.py generates predictions using several "composite"
      methods (product of CNNscore + CNNaffinity per-model, dividing score mean
      by score stdev, etc.)

    + pose\_variance\_sensitivity.py calculates AUC and EF1% when dropping
    percentiles based on variance as well as mean variance in each quartile

    + pca\_projection.py performs PCA on subsets of the data and then projects
      all the data onto to the first two principal components for plotting

    + rmsd\_plots.py takes rmsd summary files and generates clustered barplots
      showing mean performance across targets for each method vs pose rank,
      boxplots of fraction of compounds with a good pose per target, and
      jointplots of AUC or EF1% vs fraction of good poses

  > DeepChem scripts

    + train\_atomicconv.py should in theory train a DeepChem 3D Atomic
    Convolution model, but I've been having problems with it so it's a WIP

  > scripts for simple descriptor models

    + train\_simpledescriptor\_models.py fits a set of available models from
    sklearn to input data; it can also do cross validation (with types files
    provided as folds or doing a random split) and hyperparameter optimization

    + predict\_simpledescriptor\_models.py uses trained simple descriptor models,
    provided as joblib files, to make predictions for an input types file

    + dump\_fingerprints.py dumps a CSV of the fingerprints for the molecules in
    an input types file

    + make\_extra\_summary\_features.py dumps a CSV of additional features that
    match the order of a types file, used e.g. for matching the CNN predictions
    to the types files used to train/test simple descriptor models

    + make\_moltitle\_exclusionlist.py will output the list of file+molname
    instances B\A, given A=summaryfile and B=typesfile

  > figure style-related scripts

    + vspaper.mpltstyle is a matplotlib stylesheet that modifies a few things
    from the seaborn-white parameters

    + vspaper\_settings.py includes palettes, publication-ready names for
    methods, additional info that is sometimes included with targets in
    figures, markers chosen for swarmplots, and it also loads the stylesheet
    when it's included

  > accessory scripts for other tasks

    + extract\_pdbbind\_data.py generate summary data from a PDBBind index file

    + vsplot\_summary\_fordavid.py compares Vina and a user-provided CNN model
    (for the submission I used the Dense CNNaffinity model) with AUC boxplots
    on DUD-E and LIT-PCBA
